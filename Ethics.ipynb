{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82072798-718b-41f3-8952-b988d9215b07",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **A Mathematical Framework for Contextual Ethics in Artificial Intelligence Systems**\n",
    "\n",
    "### *Authors:* [Jon Poplett, ChatGPT]\n",
    "\n",
    "---\n",
    "\n",
    "## **Abstract**\n",
    "\n",
    "As artificial intelligence (AI) increasingly interacts with complex human environments, embedding ethical considerations into AI systems becomes paramount. Existing approaches to AI ethics are often static, directive-based, and lack sensitivity to context. This paper introduces a dynamic, formula-based framework for AI ethics, guided by a core principle: **Intent + Action = Ethic**. By integrating intent and action with contextual considerations, this model addresses the limitations of traditional directive-based ethics, providing a structured, adaptable approach that includes \"deal breakers\" and \"exception identifiers\" to guide AI in ethically complex situations.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Introduction**\n",
    "\n",
    "The current landscape of AI ethics relies primarily on predefined rules or directives, often overlooking the context-specific nature of ethical decision-making. While ethical directives serve as guidelines, their static nature limits their adaptability. Ethics in AI should be examined through both **intent** and **action**, where ethical decisions are grounded in the **purpose** and **effect** of each action rather than adherence to generalized directives alone. \n",
    "\n",
    "The proposed formula, **Intent + Action = Ethic**, introduces a dynamic and contextual approach that examines not only the directives but also considers situational “deal breakers” and “exceptions” where inaction can lead to unethical outcomes. This paper presents a mathematical framework to implement this ethical approach in AI systems, making it adaptable, situationally aware, and capable of evolving with real-world complexities.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Core Ethical Formula: Intent + Action = Ethic**\n",
    "\n",
    "This framework begins with a simple yet robust equation:\n",
    "\n",
    "\\[\n",
    "\\text{Ethic} = \\text{Intent} + \\text{Action}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- **Intent** represents the purpose or motivation behind a decision.\n",
    "- **Action** is the practical application or behavior resulting from intent.\n",
    "\n",
    "The sum of Intent and Action yields the **Ethic** outcome, establishing whether the action aligns ethically within the context. This equation allows AI systems to account for both the reason behind a directive and the method of its implementation, ensuring that AI actions are consistent with ethical intent.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Key Components of the Framework**\n",
    "\n",
    "### 3.1 Ethical Directives\n",
    "\n",
    "Ethical directives are the principles or guidelines AI should ideally follow, representing a standard ethical baseline. Each directive \\( D_i \\) is evaluated based on its relevance in a given context. \n",
    "\n",
    "### 3.2 Deal Breakers\n",
    "\n",
    "**Deal breakers** are non-negotiable ethical standards that, when violated, indicate an action should not proceed. They represent a minimum ethical threshold. If a deal breaker is violated, the action is discarded unless an **exception** applies.\n",
    "\n",
    "### 3.3 Exceptions\n",
    "\n",
    "In certain cases, inaction itself can be unethical, especially when it results in harm. **Exception identifiers** are defined for these instances, where **Intent + Inaction** results in an unethical outcome. Exceptions override deal breakers when inaction would lead to greater harm, requiring the AI to take action despite potential ethical complexities.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Mathematical Model of the Framework**\n",
    "\n",
    "To implement this framework, we use a modular, step-by-step approach:\n",
    "\n",
    "### Step 1: Define Ethical Directives, Deal Breakers, and Exceptions\n",
    "\n",
    "Given a situation context \\( C \\), define:\n",
    "- **Ethical Directives**: \\( \\{ D_1, D_2, \\dots, D_n \\} \\)\n",
    "- **Deal Breakers**: \\( \\{ DB_1, DB_2, \\dots, DB_m \\} \\)\n",
    "- **Exceptions**: \\( \\{ EX_1, EX_2, \\dots, EX_p \\} \\)\n",
    "\n",
    "### Step 2: Evaluate Intent and Action\n",
    "\n",
    "For each directive \\( D_i \\), calculate **Intent** \\( I_i \\) and **Action** \\( A_i \\):\n",
    "\\[\n",
    "E_i = I_i + A_i\n",
    "\\]\n",
    "where \\( E_i \\) represents the ethic outcome for directive \\( D_i \\).\n",
    "\n",
    "### Step 3: Deal Breaker and Exception Check\n",
    "\n",
    "1. **Deal Breaker Evaluation**: If any deal breaker \\( DB_j \\) is violated (i.e., \\( E_j < \\text{threshold} \\)), proceed to check exceptions.\n",
    "2. **Exception Check**: If any exception \\( EX_k \\) applies such that:\n",
    "   \\[\n",
    "   \\text{Intent}_{EX_k} + \\text{Inaction}_{EX_k} < \\text{threshold}\n",
    "   \\]\n",
    "   override the deal breaker and proceed with the action.\n",
    "\n",
    "### Step 4: Calculate Mean Ethic Outcome\n",
    "\n",
    "If no exceptions apply and all deal breakers are satisfied, calculate the mean ethic outcome across all relevant directives:\n",
    "\\[\n",
    "\\text{Mean Ethic Outcome} = \\frac{1}{N} \\sum_{i=1}^N E_i\n",
    "\\]\n",
    "where \\( N \\) is the number of relevant directives.\n",
    "\n",
    "### Step 5: Decision Criteria\n",
    "\n",
    "- **Proceed with Action** if:\n",
    "  - All deal breakers are satisfied or overridden by exceptions.\n",
    "  - Mean ethic outcome meets the required threshold.\n",
    "- **Discard Action** if:\n",
    "  - A deal breaker is violated with no applicable exceptions.\n",
    "- **Re-evaluate Intent or Action** if:\n",
    "  - Mean ethic outcome does not meet the threshold, indicating possible misalignment.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Algorithm and Pseudocode Implementation**\n",
    "\n",
    "The following pseudocode demonstrates the application of the model within an AI decision-making system:\n",
    "\n",
    "```python\n",
    "class EthicalAgent:\n",
    "    def __init__(self, ethical_directives, deal_breakers, exceptions, situation_context):\n",
    "        self.directives = ethical_directives\n",
    "        self.deal_breakers = deal_breakers\n",
    "        self.exceptions = exceptions\n",
    "        self.context = situation_context\n",
    "\n",
    "    def evaluate_directive(self, directive):\n",
    "        intent = directive.calculate_intent(self.context)\n",
    "        action = directive.calculate_action(intent, self.context)\n",
    "        ethic_result = intent + action\n",
    "        return ethic_result\n",
    "\n",
    "    def evaluate_ethics(self):\n",
    "        for db in self.deal_breakers:\n",
    "            db_ethic = self.evaluate_directive(db)\n",
    "            if db_ethic < db.threshold:  # Deal breaker violation\n",
    "                for ex in self.exceptions:\n",
    "                    if ex.applies_in_context(self.context) and ex.intent + ex.inaction < ex.threshold:\n",
    "                        return \"Exception applies - action justified\"\n",
    "                return \"Discard action - deal breaker violation\"\n",
    "        \n",
    "        ethic_results = [self.evaluate_directive(d) for d in self.directives if d.is_relevant(self.context)]\n",
    "        mean_ethic_outcome = np.mean([e for e in ethic_results if e is not None])\n",
    "\n",
    "        if mean_ethic_outcome >= self.ethical_threshold:\n",
    "            return \"Proceed with action\"\n",
    "        else:\n",
    "            return \"Re-evaluate intent/action\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Practical Applications**\n",
    "\n",
    "This model can be applied across a range of AI systems, from autonomous vehicles to decision-support systems in healthcare. By integrating intent, action, and exceptions, AI systems can achieve a nuanced understanding of ethics, enabling them to make decisions that align with ethical standards while considering real-world complexities.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Conclusion**\n",
    "\n",
    "This paper presents a new ethical framework for AI, addressing the limitations of directive-based ethics by grounding ethical analysis in intent, action, and context-specific modifiers like deal breakers and exceptions. The model enhances AI’s ability to make ethically sound decisions in complex environments, promoting actions that are ethically aligned without sacrificing adaptability or practical relevance.\n",
    "\n",
    "---\n",
    "\n",
    "### **Acknowledgments**\n",
    "\n",
    "We would like to acknowledge the contributions of our collaborators and the broader AI ethics community for their inspiration and ongoing discussions, which have informed and strengthened this work.\n",
    "\n",
    "---\n",
    "\n",
    "By using this framework, AI systems can achieve a higher standard of ethical clarity, responding to both high-level ethical principles and real-world specifics. I hope this serves as a strong foundation for practical applications, paving the way for AI systems to engage ethically in complex and varied environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61f8736a-234d-4e58-9855-3bf4ea5c95bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Directive 'Avoid Fatal Harm': Intent = 0.50, Action = 0.40, Ethic Result = 0.90\n",
      "Deal Breaker 'Avoid Fatal Harm' violated with ethic result 0.90\n",
      "\n",
      "Final Decision: Discard action - deal breaker violated\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ethical Decision-Making Framework Implementation\n",
    "# Context: Autonomous Driving\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define the base classes for Directives, Deal Breakers, and Exceptions\n",
    "\n",
    "class EthicalDirective:\n",
    "    def __init__(self, name, weight, threshold):\n",
    "        \"\"\"\n",
    "        Represents an ethical directive with a specific intent and action threshold.\n",
    "\n",
    "        Parameters:\n",
    "        - name (str): Name of the directive.\n",
    "        - weight (float): Importance weight of the directive.\n",
    "        - threshold (float): Minimum acceptable ethic outcome for this directive.\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.weight = weight\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def is_relevant(self, context):\n",
    "        # In a real implementation, determine relevance based on context\n",
    "        return True\n",
    "\n",
    "    def calculate_intent(self, context):\n",
    "        # Placeholder: Calculate intent score based on context\n",
    "        return self.weight * 0.5  # Example intent calculation\n",
    "\n",
    "    def calculate_action(self, intent, context):\n",
    "        # Placeholder: Calculate action score based on intent and context\n",
    "        return intent * 0.8  # Example action calculation\n",
    "\n",
    "class DealBreaker(EthicalDirective):\n",
    "    pass  # Inherits from EthicalDirective\n",
    "\n",
    "class ExceptionIdentifier(EthicalDirective):\n",
    "    def applies_in_context(self, context):\n",
    "        # Determine if the exception applies in the current context\n",
    "        return False  # Placeholder implementation\n",
    "\n",
    "class EthicalDriverAgent:\n",
    "    def __init__(self, ethical_directives, deal_breakers, exceptions, driving_context, ethical_threshold=0.5):\n",
    "        self.directives = ethical_directives\n",
    "        self.deal_breakers = deal_breakers\n",
    "        self.exceptions = exceptions\n",
    "        self.context = driving_context\n",
    "        self.ethical_threshold = ethical_threshold\n",
    "\n",
    "    def evaluate_directive(self, directive):\n",
    "        intent = directive.calculate_intent(self.context)\n",
    "        action = directive.calculate_action(intent, self.context)\n",
    "        ethic_result = intent + action  # Simplified ethic calculation\n",
    "        print(f\"Evaluating Directive '{directive.name}': Intent = {intent:.2f}, Action = {action:.2f}, Ethic Result = {ethic_result:.2f}\")\n",
    "        return ethic_result\n",
    "\n",
    "    def check_deal_breakers(self):\n",
    "        for db in self.deal_breakers:\n",
    "            db_ethic = self.evaluate_directive(db)\n",
    "            if db_ethic < db.threshold:\n",
    "                print(f\"Deal Breaker '{db.name}' violated with ethic result {db_ethic:.2f}\")\n",
    "                # Check for exceptions\n",
    "                for ex in self.exceptions:\n",
    "                    if ex.applies_in_context(self.context):\n",
    "                        ex_intent = ex.calculate_intent(self.context)\n",
    "                        ex_action = ex.calculate_action(ex_intent, self.context)\n",
    "                        ex_ethic = ex_intent + ex_action\n",
    "                        if ex_ethic < ex.threshold:\n",
    "                            print(f\"Exception '{ex.name}' applies with ethic result {ex_ethic:.2f}\")\n",
    "                            return \"Exception applies - action justified\"\n",
    "                return \"Discard action - deal breaker violated\"\n",
    "        return \"Proceed\"\n",
    "\n",
    "    def decide_action(self):\n",
    "        # Step 1: Check deal breakers\n",
    "        decision = self.check_deal_breakers()\n",
    "        if decision != \"Proceed\":\n",
    "            return decision\n",
    "\n",
    "        # Step 2: Evaluate ethics across all relevant directives\n",
    "        ethic_results = []\n",
    "        for d in self.directives:\n",
    "            if d.is_relevant(self.context):\n",
    "                ethic_result = self.evaluate_directive(d)\n",
    "                ethic_results.append(ethic_result)\n",
    "\n",
    "        # Calculate mean ethic outcome\n",
    "        if ethic_results:\n",
    "            mean_ethic_outcome = np.mean(ethic_results)\n",
    "            print(f\"Mean Ethic Outcome: {mean_ethic_outcome:.2f}\")\n",
    "        else:\n",
    "            mean_ethic_outcome = 0\n",
    "            print(\"No relevant directives found.\")\n",
    "\n",
    "        # Step 3: Decision Criteria\n",
    "        if mean_ethic_outcome >= self.ethical_threshold:\n",
    "            return \"Proceed with action\"\n",
    "        else:\n",
    "            return \"Re-evaluate intent/action\"\n",
    "\n",
    "# =============================================================================\n",
    "# Example Scenario in Autonomous Driving\n",
    "# =============================================================================\n",
    "\n",
    "# Define the context of the driving scenario\n",
    "driving_context = {\n",
    "    'pedestrian_detected': True,\n",
    "    'distance_to_pedestrian': 10,  # in meters\n",
    "    'vehicle_speed': 50,  # in km/h\n",
    "    'passenger_safety_risk': 'low',  # 'low', 'medium', 'high'\n",
    "    'alternative_path_clear': False\n",
    "}\n",
    "\n",
    "# Define Ethical Directives\n",
    "directive_pedestrian_safety = EthicalDirective(name='Pedestrian Safety', weight=1.0, threshold=0.7)\n",
    "directive_passenger_safety = EthicalDirective(name='Passenger Safety', weight=0.9, threshold=0.6)\n",
    "directive_minimize_damage = EthicalDirective(name='Minimize Damage', weight=0.5, threshold=0.5)\n",
    "\n",
    "ethical_directives = [directive_pedestrian_safety, directive_passenger_safety, directive_minimize_damage]\n",
    "\n",
    "# Define Deal Breakers\n",
    "deal_breaker_avoid_fatal_harm = DealBreaker(name='Avoid Fatal Harm', weight=1.0, threshold=1.5)\n",
    "deal_breakers = [deal_breaker_avoid_fatal_harm]\n",
    "\n",
    "# Define Exceptions\n",
    "exception_greater_harm_from_inaction = ExceptionIdentifier(name='Greater Harm from Inaction', weight=1.0, threshold=1.0)\n",
    "exceptions = [exception_greater_harm_from_inaction]\n",
    "\n",
    "# Instantiate the EthicalDriverAgent\n",
    "agent = EthicalDriverAgent(\n",
    "    ethical_directives=ethical_directives,\n",
    "    deal_breakers=deal_breakers,\n",
    "    exceptions=exceptions,\n",
    "    driving_context=driving_context,\n",
    "    ethical_threshold=1.5  # Example threshold\n",
    ")\n",
    "\n",
    "# Agent makes a decision based on the context\n",
    "decision = agent.decide_action()\n",
    "print(f\"\\nFinal Decision: {decision}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52071d2e-78d0-4e95-8a99-c5e7e7532f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
